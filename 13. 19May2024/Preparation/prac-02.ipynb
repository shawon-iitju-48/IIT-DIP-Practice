{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca7f05-456a-4bb2-b9f3-4b8e24544655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/ywyomOyXpxg\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    " \n",
    "#img = cv2.imread('BSE_Image.jpg')\n",
    "img = cv2.imread('images/synthetic.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "#Here, if you have multichannel image then extract the right channel instead of converting the image to grey. \n",
    "#For example, if DAPI contains nuclei information, extract the DAPI channel image first. \n",
    "\n",
    "#Multiple images can be used for training. For that, you need to concatenate the data\n",
    "\n",
    "#Save original image pixels into a data frame. This is our Feature #1.\n",
    "img2 = img.reshape(-1)\n",
    "df = pd.DataFrame()\n",
    "df['Original Image'] = img2\n",
    "\n",
    "#Generate Gabor features\n",
    "num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
    "kernels = []  #Create empty list to hold all kernels that we will generate in a loop\n",
    "for theta in range(8):   #Define number of thetas. Here only 2 theta values 0 and 1/4 . pi \n",
    "    theta = theta / 4. * np.pi\n",
    "    for sigma in (1, 3, 5, 7):  #Sigma with values of 1 and 3\n",
    "        for lamda in np.arange(0, np.pi, np.pi / 4):   #Range of wavelengths\n",
    "            for gamma in (0.05, 0.5):   #Gamma values of 0.05 and 0.5\n",
    "                           \n",
    "                gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
    "#                print(gabor_label)\n",
    "                ksize=5  #Try 15 for hidden image. Or 9 for others\n",
    "                phi = 0  #0.8 for hidden image. Otherwise leave it to 0\n",
    "                kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)    \n",
    "                kernels.append(kernel)\n",
    "                #Now filter the image and add values to a new column \n",
    "                fimg = cv2.filter2D(img2, cv2.CV_8UC3, kernel)                \n",
    "                filtered_img = fimg.reshape(-1)\n",
    "                \n",
    "                cv2.imwrite('images/gabor_filtered_images/'+gabor_label+'.jpg', filtered_img.reshape(img.shape))\n",
    "\n",
    "                df[gabor_label] = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
    "                print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "                \n",
    "                num += 1  #Increment for gabor column label\n",
    "                \n",
    "print(df.head())\n",
    "\n",
    "#df.to_csv(\"Gabor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e6724-8d11-4bbc-938e-f1ba74929dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    " \n",
    "img = cv2.imread('images/sandstone/Train_images/Sandstone_Versa0000.tif')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "#Here, if you have multichannel image then extract the right channel instead of converting the image to grey. \n",
    "#For example, if DAPI contains nuclei information, extract the DAPI channel image first. \n",
    "\n",
    "#Multiple images can be used for training. For that, you need to concatenate the data\n",
    "\n",
    "#Save original image pixels into a data frame. This is our Feature #1.\n",
    "img2 = img.reshape(-1)\n",
    "df = pd.DataFrame()\n",
    "df['Original Image'] = img2\n",
    "\n",
    "#Generate Gabor features\n",
    "num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
    "kernels = []\n",
    "for theta in range(2):   #Define number of thetas\n",
    "    theta = theta / 4. * np.pi\n",
    "    for sigma in (1, 3):  #Sigma with 1 and 3\n",
    "        for lamda in np.arange(0, np.pi, np.pi / 4):   #Range of wavelengths\n",
    "            for gamma in (0.05, 0.5):   #Gamma values of 0.05 and 0.5\n",
    "            \n",
    "                \n",
    "                gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
    "#                print(gabor_label)\n",
    "                ksize=9\n",
    "                kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)    \n",
    "                kernels.append(kernel)\n",
    "                #Now filter the image and add values to a new column \n",
    "                fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
    "                filtered_img = fimg.reshape(-1)\n",
    "                df[gabor_label] = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
    "                print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "                num += 1  #Increment for gabor column label\n",
    "                \n",
    "########################################\n",
    "#Gerate OTHER FEATURES and add them to the data frame\n",
    "                \n",
    "#CANNY EDGE\n",
    "edges = cv2.Canny(img, 100,200)   #Image, min and max values\n",
    "edges1 = edges.reshape(-1)\n",
    "df['Canny Edge'] = edges1 #Add column to original dataframe\n",
    "\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "#ROBERTS EDGE\n",
    "edge_roberts = roberts(img)\n",
    "edge_roberts1 = edge_roberts.reshape(-1)\n",
    "df['Roberts'] = edge_roberts1\n",
    "\n",
    "#SOBEL\n",
    "edge_sobel = sobel(img)\n",
    "edge_sobel1 = edge_sobel.reshape(-1)\n",
    "df['Sobel'] = edge_sobel1\n",
    "\n",
    "#SCHARR\n",
    "edge_scharr = scharr(img)\n",
    "edge_scharr1 = edge_scharr.reshape(-1)\n",
    "df['Scharr'] = edge_scharr1\n",
    "\n",
    "#PREWITT\n",
    "edge_prewitt = prewitt(img)\n",
    "edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "df['Prewitt'] = edge_prewitt1\n",
    "\n",
    "#GAUSSIAN with sigma=3\n",
    "from scipy import ndimage as nd\n",
    "gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "gaussian_img1 = gaussian_img.reshape(-1)\n",
    "df['Gaussian s3'] = gaussian_img1\n",
    "\n",
    "#GAUSSIAN with sigma=7\n",
    "gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
    "gaussian_img3 = gaussian_img2.reshape(-1)\n",
    "df['Gaussian s7'] = gaussian_img3\n",
    "\n",
    "#MEDIAN with sigma=3\n",
    "median_img = nd.median_filter(img, size=3)\n",
    "median_img1 = median_img.reshape(-1)\n",
    "df['Median s3'] = median_img1\n",
    "\n",
    "#VARIANCE with size=3\n",
    "#variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "#variance_img1 = variance_img.reshape(-1)\n",
    "#df['Variance s3'] = variance_img1  #Add column to original dataframe\n",
    "\n",
    "\n",
    "######################################                \n",
    "\n",
    "#Now, add a column in the data frame for the Labels\n",
    "#For this, we need to import the labeled image\n",
    "labeled_img = cv2.imread('images/sandstone/Train_mask_APEER/Train_masks_APEER.ome00.tif')\n",
    "#Remember that you can load an image with partial labels \n",
    "#But, drop the rows with unlabeled data\n",
    "\n",
    "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
    "labeled_img1 = labeled_img.reshape(-1)\n",
    "df['Labels'] = labeled_img1\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "original_img_data = df.drop(labels = [\"Labels\"], axis=1) #Use for prediction\n",
    "#df.to_csv(\"Gabor.csv\")\n",
    "df = df[df.Labels != 0]\n",
    "\n",
    "#########################################################\n",
    "\n",
    "#Define the dependent variable that needs to be predicted (labels)\n",
    "Y = df[\"Labels\"].values\n",
    "\n",
    "#Encode Y values to 0, 1, 2, 3, .... (NOt necessary but makes it easy to use other tools like ROC plots)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "\n",
    "\n",
    "#Define the independent variables\n",
    "X = df.drop(labels = [\"Labels\"], axis=1) \n",
    "\n",
    "#Split data into train and test to verify accuracy after fitting the model. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "\n",
    "\n",
    "# Import the model we are using\n",
    "#RandomForestRegressor is for regression type of problems. \n",
    "#For classification we use RandomForestClassifier.\n",
    "#Both yield similar results except for regressor the result is float\n",
    "#and for classifier it is an integer. \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with n number of decision trees\n",
    "model = RandomForestClassifier(n_estimators = 20, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "prediction_test = model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print (\"Accuracy = \", metrics.accuracy_score(Y_test, prediction_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
